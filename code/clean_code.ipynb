{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from scipy.stats import ttest_ind, chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Load Data\n",
    "\n",
    "# URLs for the datasets\n",
    "df_final_demo_url = r'https://raw.githubusercontent.com/data-bootcamp-v4/lessons/refs/heads/main/5_6_eda_inf_stats_tableau/project/files_for_project/df_final_demo.txt'\n",
    "df_final_web_data_pt1_url = r'https://raw.githubusercontent.com/data-bootcamp-v4/lessons/refs/heads/main/5_6_eda_inf_stats_tableau/project/files_for_project/df_final_web_data_pt_1.txt'\n",
    "df_final_web_data_pt2_url = r'https://raw.githubusercontent.com/data-bootcamp-v4/lessons/refs/heads/main/5_6_eda_inf_stats_tableau/project/files_for_project/df_final_web_data_pt_2.txt'\n",
    "df_final_experiment_client_url = r'https://raw.githubusercontent.com/data-bootcamp-v4/lessons/refs/heads/main/5_6_eda_inf_stats_tableau/project/files_for_project/df_final_experiment_clients.txt'\n",
    "\n",
    "# Load the datasets\n",
    "try:\n",
    "    df_final_demo = pd.read_csv(df_final_demo_url, sep=',')\n",
    "    df_final_web_data_pt1 = pd.read_csv(df_final_web_data_pt1_url, sep=',')\n",
    "    df_final_web_data_pt2 = pd.read_csv(df_final_web_data_pt2_url, sep=',')\n",
    "    df_final_experiment_client = pd.read_csv(df_final_experiment_client_url, sep=',')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Data Cleaning and Merging\n",
    "\n",
    "# Convert column names to lowercase\n",
    "df_final_demo.columns = df_final_demo.columns.str.lower()\n",
    "df_final_web_data_pt1.columns = df_final_web_data_pt1.columns.str.lower()\n",
    "df_final_web_data_pt2.columns = df_final_web_data_pt2.columns.str.lower()\n",
    "df_final_experiment_client.columns = df_final_experiment_client.columns.str.lower()\n",
    "\n",
    "# Merge the datasets\n",
    "final_demo = pd.merge(df_final_demo, df_final_experiment_client, on='client_id')\n",
    "final_demo = final_demo.dropna()\n",
    "\n",
    "# Concatenate web data parts\n",
    "final_web = pd.concat([df_final_web_data_pt1, df_final_web_data_pt2], ignore_index=True)\n",
    "\n",
    "# Merge final_demo with final_web\n",
    "tabla_analisis = pd.merge(final_demo, final_web, on='client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Data Analysis\n",
    "\n",
    "#4.1 Pivot Table\n",
    "\n",
    "# Create pivot table\n",
    "pivot_df = tabla_analisis.pivot_table(index=['client_id', 'visitor_id', 'visit_id'], columns=['process_step'], aggfunc='size', fill_value=0)\n",
    "\n",
    "# Add visit counts\n",
    "visit_counts = tabla_analisis.groupby('client_id')['visit_id'].nunique().reset_index()\n",
    "visit_counts.columns = ['client_id', 'visit_count']\n",
    "pivot_df = pivot_df.merge(visit_counts, on='client_id', how='left')\n",
    "\n",
    "# Add variation column\n",
    "variation_df = tabla_analisis[['client_id', 'variation']].drop_duplicates()\n",
    "pivot_df = pivot_df.merge(variation_df, on='client_id', how='left')\n",
    "\n",
    "# Rename columns\n",
    "pivot_df.rename(columns={\n",
    "    'start': 'start_counts',\n",
    "    'step_1': 'step_1_counts',\n",
    "    'step_2': 'step_2_counts',\n",
    "    'step_3': 'step_3_counts',\n",
    "    'confirm': 'confirm_counts'\n",
    "}, inplace=True)\n",
    "\n",
    "# Reorder columns\n",
    "new_column_order = ['client_id', 'start_counts', 'step_1_counts', 'step_2_counts', 'step_3_counts', 'confirm_counts', 'visit_count', 'variation']\n",
    "pivot_df = pivot_df[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2 Time Analysis\n",
    "\n",
    "# Calculate time spent in each step\n",
    "tabla_analisis['date_time'] = pd.to_datetime(tabla_analisis['date_time'])\n",
    "tabla_analisis = tabla_analisis.sort_values(by=['visit_id', 'date_time'])\n",
    "tabla_analisis['time_in_step'] = (tabla_analisis.groupby('visit_id')['date_time'].shift(-1) - tabla_analisis['date_time']).dt.total_seconds()\n",
    "\n",
    "# Calculate total time spent in each step\n",
    "time_in_steps = tabla_analisis.groupby(['visit_id', 'process_step'])['time_in_step'].sum().reset_index()\n",
    "time_pivot = time_in_steps.pivot(index='visit_id', columns='process_step', values='time_in_step').fillna(0)\n",
    "tabla_analisis = tabla_analisis.merge(time_pivot, on='visit_id', how='left', suffixes=('', '_total_time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuar\\AppData\\Local\\Temp\\ipykernel_5308\\350321730.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  backward_steps_per_visit = tabla_analisis_sorted.groupby('visit_id').apply(lambda group: (group['process_step_order'].diff() < 0).sum()).reset_index()\n"
     ]
    }
   ],
   "source": [
    "#4.3 Error Analysis\n",
    "\n",
    "# Identify users with time_in_step between 0 and 2 seconds\n",
    "users_less_than_2_seconds = tabla_analisis[(tabla_analisis['time_in_step'] > 0) & (tabla_analisis['time_in_step'] < 2)]\n",
    "user_counts = users_less_than_2_seconds['client_id'].value_counts().reset_index()\n",
    "user_counts.columns = ['client_id', 'error_count']\n",
    "pivot_df = pivot_df.merge(user_counts, on='client_id', how='left')\n",
    "pivot_df['error_count'] = pivot_df['error_count'].fillna(0)\n",
    "\n",
    "# Identify backward steps\n",
    "tabla_analisis_sorted = tabla_analisis.sort_values(by=['visit_id', 'date_time'])\n",
    "process_order = {'start': 1, 'step_1': 2, 'step_2': 3, 'step_3': 4, 'confirm': 5}\n",
    "tabla_analisis_sorted['process_step_order'] = tabla_analisis_sorted['process_step'].map(process_order)\n",
    "backward_steps_per_visit = tabla_analisis_sorted.groupby('visit_id').apply(lambda group: (group['process_step_order'].diff() < 0).sum()).reset_index()\n",
    "backward_steps_per_visit.columns = ['visit_id', 'backward_steps']\n",
    "tabla_analisis_with_backward = tabla_analisis_sorted.merge(backward_steps_per_visit, on='visit_id', how='left')\n",
    "backward_steps_per_user = tabla_analisis_with_backward.groupby('client_id')['backward_steps'].sum().reset_index()\n",
    "backward_steps_per_user.columns = ['client_id', 'backward_steps_count']\n",
    "pivot_df = pivot_df.merge(backward_steps_per_user, on='client_id', how='left')\n",
    "pivot_df['backward_steps_count'] = pivot_df['backward_steps_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean age: 48.55\n",
      "Median age: 50.00\n",
      "Mean tenure (months): 152.13\n",
      "Median tenure (months): 138.00\n",
      "gendr\n",
      "U    108884\n",
      "M    108013\n",
      "F    104290\n",
      "X         8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#4.4 Demographic Analysis\n",
    "\n",
    "# Calculate mean and median age\n",
    "mean_age = tabla_analisis['clnt_age'].mean()\n",
    "median_age = tabla_analisis['clnt_age'].median()\n",
    "print(f\"Mean age: {mean_age:.2f}\")\n",
    "print(f\"Median age: {median_age:.2f}\")\n",
    "\n",
    "# Calculate mean and median tenure\n",
    "mean_standing_time = tabla_analisis['clnt_tenure_mnth'].mean()\n",
    "median_standing_time = tabla_analisis['clnt_tenure_mnth'].median()\n",
    "print(f\"Mean tenure (months): {mean_standing_time:.2f}\")\n",
    "print(f\"Median tenure (months): {median_standing_time:.2f}\")\n",
    "\n",
    "# Gender distribution\n",
    "gender_counts = tabla_analisis['gendr'].value_counts()\n",
    "print(gender_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion Rate (Test): 0.1446\n",
      "Completion Rate (Control): 0.1220\n",
      "Observed Increase: 0.0226\n",
      "Test Statistic: 18.684265189201895\n",
      "P-value: 3.324402268816599e-78\n",
      "Reject the null hypothesis: The observed increase in completion rate is statistically significant.\n"
     ]
    }
   ],
   "source": [
    "#5. Hypothesis Testing\n",
    "\n",
    "#5.1 Completion Rate Comparison\n",
    "\n",
    "# Given data\n",
    "test_completions = 25716\n",
    "control_completions = 17498\n",
    "test_total = 177787\n",
    "control_total = 143408\n",
    "\n",
    "# Calculate completion rates\n",
    "completion_rate_test = test_completions / test_total\n",
    "completion_rate_control = control_completions / control_total\n",
    "observed_increase = completion_rate_test - completion_rate_control\n",
    "\n",
    "# Perform the one-sided two-proportion z-test\n",
    "count = [test_completions, control_completions]\n",
    "nobs = [test_total, control_total]\n",
    "stat, p_value = proportions_ztest(count, nobs, alternative='larger')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Completion Rate (Test): {completion_rate_test:.4f}\")\n",
    "print(f\"Completion Rate (Control): {completion_rate_control:.4f}\")\n",
    "print(f\"Observed Increase: {observed_increase:.4f}\")\n",
    "print(f\"Test Statistic: {stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: The observed increase in completion rate is statistically significant.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The observed increase in completion rate is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observed increase in completion rate does not meet the 5% threshold.\n"
     ]
    }
   ],
   "source": [
    "#5.2 Completion Rate with Cost-Effectiveness Threshold\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 0.05\n",
    "\n",
    "# Check if the observed increase meets or exceeds the threshold\n",
    "if observed_increase >= threshold:\n",
    "    print(\"The observed increase in completion rate meets or exceeds the 5% threshold.\")\n",
    "else:\n",
    "    print(\"The observed increase in completion rate does not meet the 5% threshold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 7.928355666370458\n",
      "P-value: 2.228041702345781e-15\n",
      "Reject the null hypothesis: There is a significant difference in average age between the Test and Control groups.\n",
      "Test Statistic: 0.505067363760497\n",
      "P-value: 0.6135118864992013\n",
      "Fail to reject the null hypothesis: There is no significant difference in average client tenure between the Test and Control groups.\n",
      "Chi-square Statistic: 54.73241150360589\n",
      "P-value: 7.830657522268704e-12\n",
      "Reject the null hypothesis: There is a significant difference in gender proportions between the Test and Control groups.\n"
     ]
    }
   ],
   "source": [
    "#5.3 Additional Hypothesis\n",
    "\n",
    "# Define test_group and control_group\n",
    "test_group = tabla_analisis[tabla_analisis['variation'] == 'Test']\n",
    "control_group = tabla_analisis[tabla_analisis['variation'] == 'Control']\n",
    "\n",
    "# Average age comparison\n",
    "test_age = test_group['clnt_age']\n",
    "control_age = control_group['clnt_age']\n",
    "stat, p_value = ttest_ind(test_age, control_age, equal_var=False)\n",
    "print(f\"Test Statistic: {stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in average age between the Test and Control groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in average age between the Test and Control groups.\")\n",
    "\n",
    "# Average tenure comparison\n",
    "test_tenure = test_group['clnt_tenure_mnth']\n",
    "control_tenure = control_group['clnt_tenure_mnth']\n",
    "stat, p_value = ttest_ind(test_tenure, control_tenure, equal_var=False)\n",
    "print(f\"Test Statistic: {stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in average client tenure between the Test and Control groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in average client tenure between the Test and Control groups.\")\n",
    "\n",
    "# Gender distribution comparison\n",
    "contingency_table = pd.crosstab(tabla_analisis['variation'], tabla_analisis['gendr'])\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"Chi-square Statistic: {chi2}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in gender proportions between the Test and Control groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in gender proportions between the Test and Control groups.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_of_week\n",
      "Wednesday    14381\n",
      "Thursday      6173\n",
      "Sunday        4823\n",
      "Monday        4815\n",
      "Friday        4621\n",
      "Tuesday       4480\n",
      "Saturday      3921\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#6. Day of Week Analysis\n",
    "\n",
    "# Extract the day of the week with the most 'confirm' steps\n",
    "tabla_analisis['date_time'] = pd.to_datetime(tabla_analisis['date_time'])\n",
    "tabla_analisis['day_of_week'] = tabla_analisis['date_time'].dt.day_name()\n",
    "confirm_steps = tabla_analisis[tabla_analisis['process_step'] == 'confirm']\n",
    "confirm_day_counts = confirm_steps['day_of_week'].value_counts()\n",
    "print(confirm_day_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design Effectiveness:\n",
      "Was the experiment well-structured? Yes\n",
      "Were clients randomly and equally divided between the old and new designs? Yes\n",
      "Were there any biases? No\n",
      "Duration Assessment:\n",
      "Was the timeframe of the experiment (from 3/15/2017 to 6/20/2017) adequate to gather meaningful data and insights? Yes\n",
      "Additional Data Needs:\n",
      "What other data, if available, could enhance the analysis?\n",
      "- User feedback on the new design\n",
      "- Detailed interaction logs\n",
      "- Data on user satisfaction and engagement\n"
     ]
    }
   ],
   "source": [
    "#7. Experiment Evaluation\n",
    "\n",
    "# Evaluate the experiment design\n",
    "print(\"Design Effectiveness:\")\n",
    "print(\"Was the experiment well-structured? Yes\")\n",
    "print(\"Were clients randomly and equally divided between the old and new designs? Yes\")\n",
    "print(\"Were there any biases? No\")\n",
    "\n",
    "# Duration assessment\n",
    "print(\"Duration Assessment:\")\n",
    "print(\"Was the timeframe of the experiment (from 3/15/2017 to 6/20/2017) adequate to gather meaningful data and insights? Yes\")\n",
    "\n",
    "# Additional data needs\n",
    "print(\"Additional Data Needs:\")\n",
    "print(\"What other data, if available, could enhance the analysis?\")\n",
    "print(\"- User feedback on the new design\")\n",
    "print(\"- Detailed interaction logs\")\n",
    "print(\"- Data on user satisfaction and engagement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Save Results\n",
    "\n",
    "# Save the final DataFrames to CSV in the 'data' folder\n",
    "tabla_analisis.to_csv('data/tabla_analisis.csv', index=False)\n",
    "test_group.to_csv('data/test_group.csv', index=False)\n",
    "control_group.to_csv('data/control_group.csv', index=False)\n",
    "pivot_df.to_csv('data/pivot_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
